# TabulaRasa BI Core **rev. 0.3**
*Real-time AdTech analytics platform*  

<p align="center">
  <img alt="Java" src="https://img.shields.io/badge/Java-17-blue?logo=openjdk"/>
  <img alt="Spark" src="https://img.shields.io/badge/Spark-3.5-orange?logo=apache-spark"/>
  <img alt="Spring Boot" src="https://img.shields.io/badge/Spring Boot-3.4-brightgreen?logo=spring"/>
  <img alt="PostgreSQL" src="https://img.shields.io/badge/PostgreSQL-14-blue?logo=postgresql"/>
  <img alt="Kafka" src="https://img.shields.io/badge/Kafka-3.7-black?logo=apache-kafka"/>
  <img alt="Docker" src="https://img.shields.io/badge/Docker-24-blue?logo=docker"/>
  <img alt="Status" src="https://img.shields.io/badge/Status-ğŸš€%20Active-success"/>
</p>

> **TabulaRasa BI Core** is a production-ready, low-latency data pipeline for large-scale AdTech workloads. From event ingestion to interactive dashboards, the project showcases modern patterns you can adapt for your own stack.

---

## ğŸ¯ Why This Repo?
* **Executives** â€” watch business KPIs update <5s after an event happens.
* **Data Engineers** â€” study a clean Spark Structured Streaming â†’ PostgreSQL upsert flow.
* **Backend Devs** â€” see a Spring Boot REST API instrumented with Micrometer.
* **DevOps** â€” spin the whole thing up with one `docker compose up`.
* **Interviewers / HR** â€” evaluate engineering craft, tests, docs, CI.

---

## ğŸ§© Architecture
Kafka (KRaft-ready) â†’ Spark Structured Streaming â†’ PostgreSQL â†’ Spring Boot API â†’ Prometheus/Grafana â†’ Flask Dashboards.

The following diagram illustrates the data pipeline architecture. The canonical source is located in `docs/mermaid_graph.md`.

```mermaid
flowchart LR
  subgraph Pipeline
    Kafka((Kafka)) --> Spark[Spark Streaming]
    Spark --> PG[(PostgreSQL)]
    PG --> API[Spring Boot REST]
    API --> Prom[Prometheus]
    Prom --> Grafana
    API --> Dash[Flask Dashboards]
  end
```

---

## âš¡ Quick Start (Local)
```bash
# 1. clone + build jars (skip tests for speed)
mvn -q clean package -DskipTests

# 2. launch full stack
docker compose -f root/docker/docker-compose.test.yml up -d

# 3. follow the logs or open dashboards
./run.sh dash        # http://localhost:8080
open http://localhost:3000 # Grafana
```
To stop everything:
```bash
./run.sh down
```

---

## ğŸ› ï¸  Tooling Highlights
| Layer | Tech | Notes |
|-------|------|-------|
| Ingestion | **Kafka 3.7** | KRaft-ready, dev-mode enabled |
| Streaming | **Spark 3.5** | Exactly-once upserts with foreachBatch |
| Storage | **PostgreSQL 14** | Composite PK, aggregated stats table |
| API | **Spring Boot 3.4** | Micrometer, Swagger UI, health endpoints |
| Dashboards | **Flask + Plotly** | Real-time HTML dashboards, dark-mode UX |
| Observability | **Prometheus + Grafana** | RED, JVM & pipeline metrics |

---

## ğŸ—ï¸ Project Structure
The codebase is organized around core data engineering challenges:

* **Q1 Real-time Stream Processing** â€” Spark Structured Streaming with Kafka
* **Q2 SQL Ad Performance** â€” Advanced analytics queries  
* **Q3 Java Refactoring** â€” Performance optimization patterns
* **Q4 API Design & Client** â€” REST endpoints with robust error handling
* **Dashboards** â€” Flask backend serving interactive Plotly visualizations
* **Docker Infrastructure** â€” Complete containerized stack with monitoring

---

## ğŸ§ª Testing
* **Unit & Integration:** `mvn test` (from `root/` directory)
* **End-to-End:** `./run.sh test` spins a full stack, streams demo events, validates counts.
* **Property-Based:** QuickTheories tests for Spark transformations.

---

## ğŸ“Š **Release Notes - rev. 0.3**
âœ… **Core Pipeline Stabilized** â€” Spark Structured Streaming with exactly-once semantics  
âœ… **Flask Dashboard Backend** â€” Real-time metrics via PostgreSQL integration  
âœ… **KRaft-Ready Kafka** â€” Modern broker configuration, dev-friendly setup  
âœ… **Comprehensive Monitoring** â€” Prometheus + Grafana + Jaeger observability stack  
âœ… **Unified Run Script** â€” Single entry point for all operations (`./run.sh`)  

âš ï¸ **Known Limitations**  
â€¢ Airflow integration commented out (ready for future orchestration needs)  
â€¢ Limited to single-node Spark cluster (easily scalable via docker-compose)  

---

## ğŸ”® Stay Tuned
Future enhancements on the radar:
* **Multi-tenant dashboards** with role-based access
* **gRPC + GraphQL APIs** for high-performance client integration  
* **Cost optimization** with columnar storage backends
* **Advanced ML features** for anomaly detection and forecasting

---

## ğŸ™Œ Contributing
PRs welcomed! Please open an issue first if it's substantial. We follow **Conventional Commits** + automated release notes.

1. Fork â†’ branch â†’ PR.
2. `pre-commit run --all` must pass.
3. One feature or fix per PR.

---

## ğŸ” License
**Creative Commons Attribution-NonCommercial 4.0 International** â€” see [`LICENSE`](LICENSE).

> Â© 2025 Alex Chernysh <alex@hireex.ai> â€” built with â¤ï¸ and caffeine.
