services:
  # ================== REUSABLE CONFIGURATIONS ==================
  x-airflow-common: &airflow-common
    image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:2.8.1}
    env_file:
      - ./airflow_setup/airflow.env
    volumes:
      - ./airflow_setup/dags:/opt/airflow/dags
      - ./airflow_setup/logs:/opt/airflow/logs
      - ./airflow_setup/plugins:/opt/airflow/plugins
      - ./spark_jars:/opt/airflow/spark_jars
    user: "${AIRFLOW_UID:-50000}:0"
    depends_on:
      tabularasa_postgres_db:
        condition: service_healthy
    networks:
      - docker_bi_network

  # ================== DATABASE SERVICES ==================
  # --► PostgreSQL for Airflow metadata and app data
  tabularasa_postgres_db:
    image: postgres:14.11-alpine
    container_name: tabularasa_postgres_db
    ports:
      - "5432:5432"
    env_file: .env
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-tabulauser}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-tabulapass}
      - POSTGRES_DB=${POSTGRES_DB:-tabularasadb}
      # Security best practices
      - POSTGRES_INITDB_ARGS=--auth-host=scram-sha-256
    volumes:
      - tabularasa_pg_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-tabulauser} -d ${POSTGRES_DB:-tabularasadb}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - docker_bi_network

  # Kafka configured for development mode
  kafka:
    image: bitnami/kafka:3.7
    container_name: kafka
    ports:
      - "9092:9092" # PLAINTEXT port
    environment:
      # Enable plaintext listener for development
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      # KRaft settings
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:9094
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_KRAFT_CLUSTER_ID=tabulaRasaBiKafkaCluster123
      # Other settings
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_CFG_ENABLE_IDEMPOTENCE=true
    volumes:
      - kafka_data:/bitnami/kafka
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics.sh --bootstrap-server localhost:9092 --list"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
    networks:
      - docker_bi_network

  kafka-ui:
    image: provectuslabs/kafka-ui:v0.7.2
    container_name: kafka-ui
    ports:
      - "8088:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local-kafka
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
    depends_on:
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8080"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - docker_bi_network

  # ================== SPARK CLUSTER ==================
  # --► Spark master and worker for distributed processing
  spark-master:
    build:
      context: ./spark
      dockerfile: Dockerfile
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - HADOOP_USER_NAME=spark
      - HADOOP_HOME=/opt/hadoop
      - HADOOP_CONF_DIR=/opt/hadoop/conf
      - JAVA_HOME=/opt/bitnami/java
      - SPARK_DAEMON_MEMORY=1g
      - SPARK_DAEMON_JAVA_OPTS="-Dhadoop.security.authentication=simple -Djavax.security.auth.useSubjectCredsOnly=false -Djava.security.krb5.conf=/dev/null"
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - spark_jars:/opt/bitnami/spark/jars
      - ../q1_realtime_stream_processing/target/q1_realtime_stream_processing-0.0.1-SNAPSHOT.jar:/opt/spark_apps/q1_realtime_stream_processing-0.0.1-SNAPSHOT.jar
    healthcheck:
      test: ["CMD-SHELL", "curl -s -f http://localhost:8080/ || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    networks:
      - docker_bi_network

  spark-worker:
    build:
      context: ./spark
      dockerfile: Dockerfile
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - HADOOP_USER_NAME=spark
      - HADOOP_HOME=/opt/hadoop
      - HADOOP_CONF_DIR=/opt/hadoop/conf
      - JAVA_HOME=/opt/bitnami/java
      - SPARK_DAEMON_MEMORY=1g
      - SPARK_DAEMON_JAVA_OPTS="-Dhadoop.security.authentication=simple -Djavax.security.auth.useSubjectCredsOnly=false -Djava.security.krb5.conf=/dev/null"
    volumes:
      - spark_jars:/opt/bitnami/spark/jars
      - ../q1_realtime_stream_processing/target/q1_realtime_stream_processing-0.0.1-SNAPSHOT.jar:/opt/spark_apps/q1_realtime_stream_processing-0.0.1-SNAPSHOT.jar
    healthcheck:
      test: ["CMD-SHELL", "curl -s -f http://localhost:8081/ || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    depends_on:
      spark-master:
        condition: service_started
    networks:
      - docker_bi_network

  # ================== AIRFLOW SERVICES ==================
  # Commented out services preserved but improved for future use

  # ================== MONITORING STACK ==================
  # --► Prometheus, Grafana, Jaeger for observability
  prometheus:
    build:
      context: ./prometheus
      dockerfile: Dockerfile
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    user: "65534:65534" # nobody:nogroup
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - docker_bi_network

  grafana:
    image: grafana/grafana:11.1.0
    container_name: grafana
    ports:
      - "3000:3000"
    user: "472"
    volumes:
      - ./grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
    env_file: .env
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
    healthcheck:
      test: ["CMD-SHELL", "wget -q -O- http://localhost:3000/api/health | grep -q '\"database\":\"ok\"'"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    depends_on:
      prometheus:
        condition: service_healthy
    networks:
      - docker_bi_network

  jaeger:
    image: jaegertracing/all-in-one:1.57
    container_name: jaeger
    ports:
      - "16686:16686" # Jaeger UI
      - "4317:4317"   # OTLP gRPC
      - "4318:4318"   # OTLP HTTP
    environment:
      - COLLECTOR_OTLP_ENABLED=true
      - SPAN_STORAGE_TYPE=badger
      - BADGER_EPHEMERAL=false
      - BADGER_DIRECTORY_VALUE=/badger/data
      - BADGER_DIRECTORY_KEY=/badger/key
    volumes:
      - jaeger_data:/badger
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:16686"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - docker_bi_network

  alertmanager:
    build:
      context: ./alertmanager
      dockerfile: Dockerfile
    container_name: alertmanager
    ports:
      - "9093:9093"
    volumes:
      - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - alertmanager_data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
    user: "65534:65534" # nobody:nogroup
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9093/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - docker_bi_network

volumes:
  tabularasa_pg_data:
    driver: local
  kafka_data:
    driver: local
  spark_jars:
    driver: local
  prometheus_data:
    driver: local
  jaeger_data:
    driver: local
  alertmanager_data:
    driver: local
  grafana_data_vol:
    driver: local
  airflow_volume:
    driver: local

networks:
  docker_bi_network:
    driver: bridge
    name: tabularasa_bi_network 